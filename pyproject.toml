[project]
name = "indextts"
version = "2.0.0"
description = "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech"
authors = [{ name = "Bilibili IndexTTS Team" }]
license = "LicenseRef-Bilibili-IndexTTS"
license-files = ["LICEN[CS]E*", "INDEX_MODEL_LICENSE*"]
readme = "README.md"
classifiers = [
  "Development Status :: 5 - Production/Stable",

  "Intended Audience :: Science/Research",
  "Intended Audience :: Developers",

  "Topic :: Scientific/Engineering",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",

  "Natural Language :: English",
  "Natural Language :: Chinese (Simplified)",

  "Programming Language :: Python :: 3",

  "Operating System :: OS Independent",
]
requires-python = ">=3.10"
dependencies = [
    # IMPORTANT: Always run `uv lock` to resolve and update the lockfile after edits:
    "accelerate==1.8.1",
    "setuptools",
    "cn2an==0.5.22",
    "cython==3.0.7",
    "descript-audiotools==0.7.2",
    "ffmpeg-python==0.2.0",
    "g2p-en==2.1.0",
    "gradio>=5.44.1",
    "jieba==0.42.1",
    "json5==0.10.0",
    "keras==2.9.0",
    "librosa==0.10.2.post1",
    "matplotlib==3.8.2",
    "modelscope==1.27.0",
    "munch==4.0.0",
    "numba==0.58.1",
    "numpy==1.26.2",
    "omegaconf>=2.3.0",
    "opencv-python==4.9.0.80",
    "pandas==2.3.2",
    "safetensors==0.5.2",
    "sentencepiece>=0.2.1",
    "tensorboard==2.9.1",
    "textstat>=0.7.10",
    "tokenizers==0.21.0",
    "tqdm>=4.67.1",
    "transformers==4.52.1",
    # Use "wetext" on Windows/Mac, otherwise "WeTextProcessing" on Linux."
    "wetext>=0.0.9; sys_platform != 'linux'",
    "WeTextProcessing; sys_platform == 'linux'",
    "deepspeed",
]

[project.optional-dependencies]
cu128 = [
  "torch>=2.7.1",
  "torchvision>=0.22.1",
  "torchaudio>=2.7.1",
  "deepspeed==0.17.1",
]

# To install the WebUI support, use `uv sync --extra webui` (or `--all-extras`).
webui = [
  "gradio==5.45.0",
]
# To install the DeepSpeed support, use `uv sync --extra deepspeed` (or `--all-extras`).
deepspeed = [
  "deepspeed==0.17.1",
]

[project.urls]
Homepage = "https://github.com/index-tts/index-tts"
Repository = "https://github.com/index-tts/index-tts.git"

[project.scripts]
# Set the installed binary names and entry points.
indextts = "indextts.cli:main"

[build-system]
# How to build the project as a CLI tool or PyPI package.
# NOTE: Use `uv tool install -e .` to install the package as a CLI tool.
requires = ["hatchling >= 1.27.0"]
build-backend = "hatchling.build"

[tool.uv]
# Disable build isolation when building DeepSpeed from source.
# NOTE: This is *necessary* so that DeepSpeed builds directly within our `.venv`,
# and finds our CUDA-enabled version of PyTorch, which DeepSpeed *needs* during
# its compilation to determine what GPU support to compile for itself. It also
# saves time, since it won't waste time downloading a generic PyTorch version.
no-build-isolation-package = ["deepspeed"]
override-dependencies = [
  "click==8.2.1",
  "wheel==0.45.1"
]


[tool.uv.sources]
torch = [
  { index = "pytorch-cu128", extra = "cu128" },
]
torchvision = [
  { index = "pytorch-cu128", extra = "cu128" },
]
torchaudio = [
  { index = "pytorch-cu128", extra = "cu128" },
]
deepspeed = { path = "deepspeed-0.17.1+2ce55057-cp310-cp310-win_amd64.whl" }

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true
